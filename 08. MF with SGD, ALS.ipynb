{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 00. 환경설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "import numpy as np\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "%matplotlib inline\n",
    "\n",
    "from surprise import KNNBasic, KNNWithMeans, SVD\n",
    "from surprise.model_selection.validation import cross_validate\n",
    "\n",
    "from IPython.display import Image\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01. Matrix Factorization 구현\n",
    "- SGD 최적화를 이용하여 MF 모델의 파라미터를 업데이트한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964981247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964983815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964982931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100831</th>\n",
       "      <td>610</td>\n",
       "      <td>166534</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1493848402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100832</th>\n",
       "      <td>610</td>\n",
       "      <td>168248</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1493850091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100833</th>\n",
       "      <td>610</td>\n",
       "      <td>168250</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1494273047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100834</th>\n",
       "      <td>610</td>\n",
       "      <td>168252</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1493846352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100835</th>\n",
       "      <td>610</td>\n",
       "      <td>170875</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1493846415</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100836 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        userId  movieId  rating   timestamp\n",
       "0            1        1     4.0   964982703\n",
       "1            1        3     4.0   964981247\n",
       "2            1        6     4.0   964982224\n",
       "3            1       47     5.0   964983815\n",
       "4            1       50     5.0   964982931\n",
       "...        ...      ...     ...         ...\n",
       "100831     610   166534     4.0  1493848402\n",
       "100832     610   168248     5.0  1493850091\n",
       "100833     610   168250     5.0  1494273047\n",
       "100834     610   168252     5.0  1493846352\n",
       "100835     610   170875     3.0  1493846415\n",
       "\n",
       "[100836 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_df = pd.read_csv(\"../data/ml-latest-small/ratings.csv\", encoding='utf-8')\n",
    "ratings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x20b121025c8>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEGCAYAAAB1iW6ZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3deXhc1X3/8fd3tC+jzdol2/Iuy9hgWxgIBgIEMGQhJSQhEAJZSpOGBNK0+SXpr0nDr336JG3TlJKNAGEJa5YmBJNg1tjEeJFXbEveZVv7Lo22kTRzfn/MjCLLI2mWK419/X09jx6kmTuaM8b+zJnv/Z5zxRiDUkqpc58j1gNQSillDQ10pZSyCQ10pZSyCQ10pZSyCQ10pZSyifhYPXFubq4pKyuL1dMrpdQ5aceOHW3GmLxg98Us0MvKyqiqqorV0yul1DlJRE5MdJ+WXJRSyiY00JVSyiamDHQRSRaRbSKyR0T2i8h3ghyTJCLPi8gREdkqImXTMVillFITC2WG7gauMcZcCFwErBORS8cd81mg0xizEPgv4LvWDlMppdRUpgx049Pr/zHB/zV+A5ibgSf83/8KuFZExLJRKqWUmlJINXQRiROR3UAL8KoxZuu4Q0qAUwDGmBGgG5hl5UCVUkpNLqRAN8Z4jDEXAaXAGhG5YNwhwWbjZ2zjKCL3iEiViFS1traGP1qllFITCqvLxRjTBbwFrBt3Vx0wG0BE4oFMoCPI4x82xlQaYyrz8oL2xSullIpQKF0ueSKS5f8+BXgfUDPusBeBu/zf3wq8YXSjdaWUmlGhrBQtAp4QkTh8bwAvGGNeEpEHgCpjzIvAo8BTInIE38z8tmkbsVIqpp7ZejLo7bdfMmeGR6LGmzLQjTF7gZVBbv/WmO8HgY9aOzSllFLh0JWiSillExroSillExroSillExroSillExroSillExroSillExroSillExroSillExroSillExroSillExroSillExroSillExroSillExroSillExroSillExroSillExroSillExroSillExroSillExroSillExroSillExroSillExroSillExroSillExroSillExroSillE1MGuojMFpE3RaRaRPaLyH1BjnmviHSLyG7/17emZ7hKKaUmEh/CMSPAV40xO0XECewQkVeNMQfGHbfJGPMB64eolFIqFFPO0I0xjcaYnf7vXUA1UDLdA1NKKRWesGroIlIGrAS2Brn7MhHZIyJ/EJFlFoxNKaVUGEIpuQAgIunAr4H7jTE94+7eCcw1xvSKyE3Ab4FFQX7HPcA9AHPmzIl40Eoppc4U0gxdRBLwhfnTxpjfjL/fGNNjjOn1f/8ykCAiuUGOe9gYU2mMqczLy4ty6EoppcYKpctFgEeBamPM9yc4ptB/HCKyxv97260cqFJKqcmFUnK5HLgTeFdEdvtv+yYwB8AY8xPgVuALIjICDAC3GWPMNIxXKaXUBKYMdGPM24BMccxDwENWDUoppVT4dKWoUkrZhAa6UkrZhAa6UkrZhAa6UkrZhAa6UkrZhAa6UkrZhAa6UkrZhAa6UkrZhAa6UkrZhAa6UkrZhAa6UkrZhAa6UkrZhAa6UkrZhAa6UkrZhAa6UkrZRMjXFFVKBffM1pNn3Hb7JXrNXDXzdIaulFI2oYGulFI2oYGulFI2oYGulFI2oYGulFI2oYGulFI2oYGulFI2oYGulFI2oYGulFI2oYGulFI2MWWgi8hsEXlTRKpFZL+I3BfkGBGRB0XkiIjsFZFV0zNcpZRSEwllL5cR4KvGmJ0i4gR2iMirxpgDY465EVjk/7oE+LH/v0oppWbIlDN0Y0yjMWan/3sXUA2UjDvsZuBJ47MFyBKRIstHq5RSakJh1dBFpAxYCWwdd1cJcGrMz3WcGfpKKaWmUciBLiLpwK+B+40xPePvDvIQE+R33CMiVSJS1draGt5IlVJKTSqkQBeRBHxh/rQx5jdBDqkDZo/5uRRoGH+QMeZhY0ylMaYyLy8vkvEqpZSaQChdLgI8ClQbY74/wWEvAp/yd7tcCnQbYxotHKdSSqkphNLlcjlwJ/CuiOz23/ZNYA6AMeYnwMvATcARoB/4tPVDVUopNZkpA90Y8zbBa+RjjzHAF60alFJKqfDpSlGllLIJDXSllLIJDXSllLIJDXSllLIJDXSllLIJDXSllLIJDXSllLIJDXSllLIJDXSllLIJDXSllLIJDXSllLIJDXSllLIJDXSllLIJDXSllLIJDXSllLIJDXSllLIJDXSllLIJDXSllLIJDXSllLIJDXSllLIJDXSllLIJDXSllLIJDXSllLIJDXSllLIJDXSllLIJDXSllLIJDXSllLKJKQNdRB4TkRYR2TfB/e8VkW4R2e3/+pb1w1RKKTWV+BCOeRx4CHhykmM2GWM+YMmIlFJKRWTKGboxZiPQMQNjUUopFQWrauiXicgeEfmDiCyb6CARuUdEqkSkqrW11aKnVkopBdYE+k5grjHmQuB/gN9OdKAx5mFjTKUxpjIvL8+Cp1ZKKRUQdaAbY3qMMb3+718GEkQkN+qRKaWUCksoJ0UnJSKFQLMxxojIGnxvEu1Rj0wpFbJntp4847bbL5kTg5HY07ny5ztloIvIs8B7gVwRqQO+DSQAGGN+AtwKfEFERoAB4DZjjJm2ESullApqykA3xnxiivsfwtfWqJRSKoZ0pahSStmEBrpSStmEBrpSStmEBrpSStmEBrpSStmEBrpSStmEBrpSStmEBrpSKmIb9jfxHxsOsqeuC11PGHsa6EqpiB1r66Ojb4jnt5/itoe3MDDkifWQzmsa6EqpiHX2DbFqThbrlhWy9XgH7xxri/WQzmsa6EqpiAyNeHG5R8hJS+Ki2VkA1HcNxnhU5zcNdKVURDr7hwDISUsgPTmehDihoWsgxqM6v2mgK6UiMhroqYk4RCjKTKG+UwM9ljTQlVIR6ezzBXp2WiIAxVnJOkOPMQ10pVREOvqGSIgT0pN8u3AXZ6VooMeYBrpSKiKd/cNkpyYiIgCUZqXQ1DPIsMcb45GdvzTQlVIR6ewfIjs1cfTn4qwUvAaae7TTJVY00JVSYTPG0NE3RE7a6YEO0KCtizGjga6UCtvAkAf3iHf0hChASbYv0Ou7+mM1rPOeBrpSKmwdoy2LCaO3FWfqDD3WNNCVUmHrGNeyCJCSGEdOWiL12ukSMxroSqmwdfYPA75FRWOVZOnioljSQFdKha2jb4jUxDiSEuJOu10XF8WWBrpSKmyd/ad3uAQEFhfp3uixoYGulApbZ9/pPegBJVkp9A156B4YjsGolAa6UiosXmPo6h8OOkMvyQq0LmrZJRamDHQReUxEWkRk3wT3i4g8KCJHRGSviKyyfphKqbNFr3sEjzFkpiSccZ8uLoqtUGbojwPrJrn/RmCR/+se4MfRD0upc9POE508t/1krIcxrXoHRwBGN+Uaa3RxUacuLoqFKQPdGLMR6JjkkJuBJ43PFiBLRIqsGqBS5wpjDG8damFvXbet9zPpc08c6LPSEkmMd9DQbd/XfzazooZeApwa83Od/7YziMg9IlIlIlWtra0WPLVSZ4/6rgHaen0LbrYdn2wOdG7rnSTQRYTizGQaNdBjwopAlyC3Be1ZMsY8bIypNMZU5uXlWfDUSp099pzqIs4hJMY5zo9ATz4z0AFy05Noc7lnckjKL/j/kfDUAbPH/FwKNFjwe5U6Z3i8hj113SwpcDLs8do+0OMdQlJ88PlgbnoSR1t7Z3hUCqyZob8IfMrf7XIp0G2MabTg9yp1zjjW2kuve4SLZmdRlpvGwWYXXf4NrOymd3CEtKT40QtbjDcrPZH2Pnu+9rPdlDN0EXkWeC+QKyJ1wLeBBABjzE+Al4GbgCNAP/Dp6RqsUmer3ae6SE5wsKTQSVqn75/V9tpOrqsoiPHIrNc3NBK0fh6Qm55EZ/8QIx4v8XHTs9Tlma3BO4luv2TOtDzfuWLKQDfGfGKK+w3wRctGpNQ5xhjDgcYeLijOJCHOQWl2ir+O3m7LQO8dHMGZfGYPekBueiLG+LbYzXcmz+DIlK4UVSpKve4R3CNeirN84ZUQ5+Ci2Vlsq+2M8cimR6976hk6QJtLyy4zTQNdqSh1BtkbfM28HPbVd4/2bNuFMcYX6BN0uADkOn2B3t6nnS4zTQNdqSgF9gYfu1nVxfNy8HgNu052xWpY06J7YBivgbRJZuiz/G9sbb0a6DNNA12pKHX6u1nGBnp5oROA4232at8LLJyatOTi1JJLrGigKxWlzv4h0hLjSBzTl52XnkRinIN6m21SFZh1TxbozqR4EuMctGnJZcZZsbBIqVHnYztZZ//wafVzAIdDKMpKtt02sqEEuoiQm56oM/QY0Bm6UlGa6GIPxZkpttt1sD1QcpnkpCjArPQkPSkaAxroSkXB6/Vd7CE79cy+7JLsFFvO0AVITYyb9Ljc9EQ9KRoDGuhKRaHZNYjHmDNKLuC7ek+Ly83QiDcGI5sebb1uUpPicUyw7D/At0GXllxmmga6UlGo6/TNwINeXzM7BWOgsds+s/S23iGck9TPAwIlF71Y9MzSQFcqCnX+GnmwQC+14fU123rdpCVNXm4BX8ll2GPoGbDXwqqznQa6UlE41eEL66wgNfTA9TXrO+0V6JN1uASMLv/XE6MzSgNdqSjUdfbjTI4nIciugkX+vV3sNENv7x0KL9D1QhczSgNdqSic6hgIWm4BSIqPI9+ZZJsZev/QCP1DntAC3en7M9F90WeWBrpSUajr6g/ashhgp9bFUHvQAWal+Wfo2ro4ozTQlYrQiMdLQ9fghDN08LUuNtgk0Fv94TzZxlwBOWmJiNi35OI1hgMNPbEexhk00JWKUFPPIB6vmTzQs1No6BrE6z332/cC4RxKySXOIeSkJtJm05LLlmPt3PTgJnacOLuuHauBrlSERnvQgywqCijJSmHI452R0oMxBvewZ9p+f6AeHkqgQ2Bxkf1m6F5jeOdoOwBPvnMixqM5nQa6UhH6y6KiSWro/tbFumkuu/QPjfDEO7X82x9rcA0OT8tztIYxQwf7Xiz6cLOL9r4h5uem8fK7jaN/LmcDDXSlIhToXslMmfyk6Nhjp8P+hm5++OYRjrT0MjTi5VCza1qep6lnkJy0xJAv/JybnmTLk6LvHGvHmRTPjz+5mmGP4YWqU7Ee0igNdKUi1NA1QJ4zadKAK5mB1aJfeX43Hq/hb65cQEZyPDVN0xPoLT2D5PsvXhEKO5Zc2lxuDjX3smZeDksKnaxdmMvTW04w4jk79uvR/dCV7czUnuwN3QOjq0En4kxOICM5fto6XTr6hjjU3MsNFQXMzkllSaGTvXXdjHitD5imnkEKM5NDPj7XmUjfkIf+oRFSE+0RNVuOtxMnwpp5OQB88tK5fP4XO3i9poUblhXGeHQ6Q1cqYvVdA5RkTR1wxVkp01Zy2XWyE4DZs1IBWFKQgXvEy4l26/dhb+5xU+AMPdALM5JHH2cXR1p6WZifjjPZV2Z739J8slITeL26OcYj89FAVyoCxhgaugZGSyqTKZ3GxUU7T3YS5xBKs3yBviA/jTiHcNDissuwv1OnIIwZemA2b5fdJgN/BsVj3sTj4xxUFGVY/ucdKQ10pSLQ2T/M4LB3ypIL+Oro0zVD33mii4qijNHrmSbFxzEvN42DFp8Ybet1YwwUZIReQy/K9P3ZNHXb47qqrS43XgOFmaf/Py8vzOBgswvPWbDWQANdqQgEauIhBXp2Ci73CN0D1rYTjni87KnrYtWcrNNuX1LgpNXl5lSHdWWXQCgHyiihCBzbaJNAn+jPoLzIyeCwlxPtfbEY1mlCCnQRWSciB0XkiIh8Pcj9d4tIq4js9n99zvqhKnX2CPSgh1JyKfGXQ6yepdc0uegf8rBqbvZpt5cXOgF462CLZc8VqIMXhBHoKYlxZKUm2GaG3tQzSLxDmJV++kKypYUZANPWXRSOKQNdROKAHwI3AhXAJ0SkIsihzxtjLvJ/PWLxOJU6q4Q7Qx/7GKsEToiumnN6oM9KTyI9KZ69dd2WPVdzjy+Uwwl08M1m7TRDL8hIPuPye4sK0nEI1DTGfm+XUGboa4Ajxphjxpgh4Dng5ukdllJnt4auAZITHJOuEg0onqZ90Xee7CLPmURp9plvKoWZyZbOGJsDs9NJtjkIpjAzefTN4FzXOEHbZnKC77xF9bkwQwdKgLFLoer8t433ERHZKyK/EpHZwX6RiNwjIlUiUtXa2hrBcJU6OzR0+zpcZIqLJQPkpiWRGO+wPNB3nOhk9ZzsoGMozEjmULPLsgUvzT1u8p1JOBxTv96xijLtMUN3DQ7T5x6Z8BxCeVEGNU3nxgw92P/B8adzfw+UGWNWAK8BTwT7RcaYh40xlcaYyry8vPBGqtRZpL5rMKRyC4DDIZZ3urT1ujnZ0c+quVlB7y/MTMY94qXWohN1zT2D5IdZbgEozEihrdfN0MjZsZIyUk3+TxkTLaxaWujkVMfAtO2jE6pQAr0OGDvjLgUaxh5gjGk3xgRWD/wMWG3N8JQ6O4Xagx5QkpVi6QZd79b76uMXlk4Q6P7wrW60pgzQ3DMYVodLQFFmYHHRuT1Ln6rLp9x/YnS69tEJVSiBvh1YJCLzRCQRuA14cewBIlI05scPAdXWDVGps8vgsIdWlzvkGTpYf6GLGn9QLy3OCHp/vjOJeIdYVgZo6hkMqwc9IDCjbbJBoGckx094cY/yIl9nkVVvoJGaMtCNMSPAvcAr+IL6BWPMfhF5QEQ+5D/syyKyX0T2AF8G7p6uASsVa4HZWjiBXpyVQqvLzaBF+5VXN/ZQkpVCRnLwk7LxcQ4W5KWPBn80+odGcA2OhLVKNKAoc/p60Q82ufjFlhP0zECZY6p9bEqyUnAmxce8jh7SjjnGmJeBl8fd9q0x338D+Ia1Q1Pq7PSXlsXQAy7QutjYPci83LSox1DT1MNS/6xwIuVFTqpqO6N+rkAPeiQll8CbQJPFy/89XsOLe+rp7B+moWuAu95TFnZLZaiGPV5aXG4W5adPeIyIUF7kjPkWALpSVKkwBbpVwq2hgzWLi9wjHo629o3WbSdSXphBfdcA3f3RzWAj7UEHcCbFk5YYR1O3tRt07TrZSWf/MNdXFODxGn668ei0lXWOt/Xh8Zopd5osL8ygptGFMbHbAkADXakwNXQNIjJxx0MwgV7x+q7ol+MfaenF4zWjdduJBGbw0ZYBogl0EaEwM5mmHutm6EMjXt482EJpdgpXLc7j81ctwOM1bD3WbtlzjFXtXzBUmDH5G3h5kROXe2Ra976figa6spzXGJ7YXMvP/3ycQ82xnbFMh4auAfLSk0iKjwv5MYWZyYhYM0MP1MWnmqEvLbJmSfpfAj38k6Lg26TLyhr6r3fW0dk/zLXl+YgI2WmJLMp3Ut3YMy0X465pchEnQq5z8kVVgf8fVpy3iJQGurLcgYYeDja7ONnRz+Oba/npxmMMnyVXdLFCfdcARWGUWwAS4hwUOJOp74o+2GqaekiKd1Dm3wN9IvnOJLJTE6KeoTd1u0lLjBvdAzxchZnJlu3nYozhJ386Sml2CosL/vIJZVlxBj2DI+yp67LkecaqaezxXZnKMXlcLim05hNRNDTQlaW8xvBadTN56Ul886alrFtWyMmOft46aJ+VwUdbe5kfwYnNkuwUS0ouNU0uFhc4p7y2p4hQXpjBgShnjM2uwahOOBZlJtPicluyavVoax8n2vtZPff0FbLlhRk4BF7Zb/2FJmqaXCGV19KT4pmTkxrTLQA00JWl9tV30+Jyc83SfBLiHFy+MBdncjzPbw9+WbhzTc/gMI3dgywqmLjjYSIlWdZc6KK60TW6o+JUKoozqGnsiSpMm7ujC/TCzGQ8XkNb71DEvyNg4yHfxGBx/umvPyUxjvl56byyv8nSEl9X/xCN3aEvqiovdMZ0ky4NdGUZj9fwenUL+c4klpdkAhDnEFbNyeaNmhZbbKN6uLkXODNQQlGSnUJj12BUF0Jodblp63VTXjR5/TxgRWkm7hEvh1t6I37O+q6B0X7ySPxlX/To38w2Hm5lfm4a2UE2CasoyuB4W19Ur3W8wPmHUE+Al/vHYNV6g3BpoE+jZ7aeDPplV2/WtNDa6+aa8vzTthitnJuN1/hOZp3rAku7l4Q4Qx6rNDuFEa+Jqr0u0Oe8NMTnD7yxvhvhVrrdA4FPJOG/3oDR1aJRvqEPDnvYcqydKxcH3weqwv8m98q+pqieZ6zAbDvUQF9a6MRr/vLGP9M00JVl/ri/ieQEB8uKM0+7fVZ6EpfNn8ULVaempQthvOrGHnad7JyW7ppDzS5SEuLC6kEPCJzEi+YjeeCEW6hvKGWz0nAmxbO3PrKThYE3sFBLPMEU+y/ZVhdlh09VbSeDw16uXJwb9P6MlARWzsniVQsv2FzT5CInLRHnBEv+xwt8cqqO0YlRDXRliRGPl9ermykvzCAuyBarH794Nifa+9lyfHp6hQPePNjC01tP8MsddfxyR53lu/wdbu71XdAgzG1kwddGKAL7GyL/x76vvpuCjCRmpYfWQuhwCBeUZEY8Qw98IojkE0lAdloi+c6kqENu4+FWEuMcXDp/1oTHXL0kn3fru2nvtWYhU3WT73xFKNskA8zJSSUlIS5mrYsa6MoS22t9K/cqJqjtrrugkNTEONbvbZy2Meyr7+aLT++kMCOZa8rz2XOqi5/86ail9cxDzS4WRVA/B18XRNmsNA5EEehVJzrPuELRVFaUZlLd6Iroze1gkwtncnxUNXTwtRVG87rBd0K0siyb1MSJZ8tXLs7DGHj7SFtUzwW+c0KHmlxT9vuPFecQFhc6Y9a6qIGuLLHhQBOJ8Y4Juz+SE+J475I8Xj3QPC1ll+6BYT77xHayUhL41GVlvG9pAZ+8dC5NPYNsO95hyXN09Q/R4nKzOIIOl4CKogz2N0Y2W27qHqSuc4DKspywHre8NJMhjzeirV0PNrtYUhD6DHUiFcUZHGnpjfjNtblnkJom14T184DlJZlkpSaw8VD0gX6ivY+BYc+UK3LHW1roW+QUiwV1GugqasYYNuxv5spFuZOunry+opAWl3taFn+8sP0UzT1ufnjHKjJSfAtglhZlsCAvjc1H2yzpgT4U6HCJovxQUZzBqY4BugfC31+l6oTvjalybpgz9BLfnunhXmPUGMPBJldUrzdgWXEmI14T8cnCP/nXMVy5aPJAj3MIaxfmsulwa9SBWjN6Ajr0GTr4zjd09g/T6rJ2/5pQaKCrqO1v6KG+a4DrKwonPe7q8nziHcKGA9Yu/hjxeHl8cy1r5uWwclw54opFeZatIAzMcBdH0fFR4d+/vDqCE6NVtZ2kJMSN/o5Qzc5JITMlYfSiGKFq7nHTPTAc1QnRgEApbn9DZJ9OXq9ppjgzecodJsEX+i0ud9RbHhxo6MEhhL3mIHBi9EAM+tE10FXUNuxvwiFw7dL8SY/LTEngsgWzeGW/dW1lAK9VN1PfNcBnLi87475F+ekUZiSz6XBb1KWew80u0pPiKY6inrysOBBsEQT6iQ4ump1FwhQrRMcTEVaUZvJumJ0uBy14AwuYk5NKelJ8RCE3OOxh0+E2rlmaH1Lp5wp/F0xgEVKk3jnWzvLSLJITQt+zB+CCkkziHWJZqS8cGug2N9298MYYXnq3kYvLckLqvLi+ooBjrX0csXDxx2N/rqU0O4XrgnxCEBGuWJRLi8vNW4daonqeQ829LMxPj6qenO9MJs+ZFPZMtdc9woGGHi4uC6/cErC8JJODTa6watgHAy2SFgS6wyEsLXJG9Ea29XgH/UMeri0vCOn4oswUFheks/Fw5IHeMzjM7lNdXLEweIvkZNKT4lk1J5tNh6Ov44dLA11FZX9DD8da+/jwypKQjg+E7oYD1szS99V3s+14B3ddVha0XRJgRWkWmSkJPPZ2bVTPdbjFFdUJ0YCKovA7Pnaf7MJrYHWYJ0QDlpdkMuwxYZV6Djb1+jb4CrIqMxIVRRkR7Yj4RnUzyQkOLlswcbvieFcuymP78U4GhiI7CbvlaDser2HtovADHeCKRbnsa+imoy/67Q7CoYGuovK73fUkxAk3XjB5/TygMDOZC2dn8fK71rQv/vzPtaQmxvGxi2dPeEycQ7hkXg5vH2njSEtkddX2XjdtvUOWlB+W+Ts+3COhh03ViQ4cAqvmBL8o9FTWzMshziG8Xh36p5SDzT1R9Z+Pt6w4k/4hD7XtfSE/xhjDa9UtrF2YF1bp4+ryfIY8Xl6viex8zabDbaQmxoXdIhqwdlEuxsCfLWifDMd5F+gzvRS/Z2CYqtoOnt12klf2N1m+0CWWfJcBa+CqxflkpYY+i7tlZQn76nvYF+ZJuvFaXW5+v6eBW1eXkpky+daulWU5JMY7eGLziYieK/DxffxJ10gEOj4ONYVedqqq7WRJYUbEW9jOSk/i0vk5vPxuY0jdHx5/R4oV5ZaAigjOHxxq7qW+a2DK8zPjXTp/FkWZyfxqR2TbTbx9pI1L5vn+zkRiRWkWGcnxbIqi7BOJ8y7QZ9Leui6+90oNv9lVz/G2Pv50qJUH3zjM5qMzX1ubDluPt9Pc4+bDK4vDetyHV5aQnODg6SjfTJ/eeoIhj5e73lM25bHpSfF8cEUxv95ZF9FFhdfvbaQ4M5mVsyObIY8VCLYDIfajDw572HWyM+x2xfFuWl7Esba+kLo/atv7cI94LZ2hLypIJ94hYZ0YDcywrykPL9DjHMItq0rYeKh19AIdoarr7Od4Wx9rp2iRnOr51y7KZdPhthntR9dAnyav7G/ihapTzM5J5UvXLOQbN5bz11fMR4A7HtnKqxa37sXC73Y1kJYYF/LJqoDMlAQ+uKKY3+2uxxXhFdvdIx5+seUkVy/JY0FeaHXtu99TRv+Qh19VhTdr6x4YZuOhNm5aXhTRkv/x5uakMistMeTyx+/3NNA35Am5rDWRG5YV4hBCKne95v/7uSrKN5GxkuLjWJifHvIM3es1/GZnPReWZka0fe+tq2fjNfC/u+rDetzb/pOZV0ZYPw9YuzCPxuKu24oAAA+9SURBVO5BjrbO3EZdGujT4E+HWrn3mZ2UZKVw12VlFGWmICLMy03jS9csYnlJJvc9tyvintxwebwGr8WzhP6hEV7e18gNFxSSkhheWxfAHZfOpX/Iw+92N0T0/C/taaSt182nL58X8mOWl2ayak4WT7xTG9YVlF490MyQx8v7VxRFMNIzORzCrZWlvFbdPOWWssYYnnznBIvy08M6KRhMbnoSl86fxfopyi7GGJ7ddpKLy7JDfrMM1aXzZ7HlaHtIi242HGjmSEsvn1kb+v/jseblplE5N5tfVp0Ka5a86UgbBRlJLMyP7rVf4X9DmMluFw10ix1scvHFp3eyMN/J3e+Zd8aJnMR4B498qpLMlAQ+90RV2B8HQ+H1Gn61o44rv/cm//TbffzT7/bxvT/WsOVYuyUrJgF+8tZRXIMj3HHJ3Igef2FpJhVFGTy99WTYH0k9XsMjbx9nYX766D+aUN17zUJOtPfz6NvHQ37M+r0NlGSlcJEF5ZaAO9bMxQDPbjs16XG7T3Xxbn03n7psbtTL7wFuXF7Esda+0R7zYN452k5tez+fWDMn6ucb71OXzWXY6+Wpd2onPc4Yw4/fOsKcnFTevzzyN9KPVpZytLWP3adC68H3fRprZe3CvKj/vGfnpDIvN40/7LP2ohuTsX2gD3u8bNjfxAO/P8CHHnqbxzcf508HWyzZbH+8tl43n3l8O6mJcTx2d+WEM9f8jGQeuauS7oFh7v759ohquhPZV9/Nh374Nn//yz1kpyawdlEu1y7NJyctkRf3NPD91w5F/RGwrrOfn248xgcvLGZ1hB/JRYQ7Lp1DdWNP2OWnn248SnVjD1++dlHY/+iuKS/guooC/vu1wyFdPai7f5hNh9v4wIoiSwI1YM6sVK5anMdz205O+mnhyXdOkJ4Uz1+tKrXkedf5yy6/3zPxJ6Nntp0kMyWBm6II0onMz0vn2vICntpyYtKe+M1H29lT183nr1ow5aX2JnPT8iJSEuL40VtHQwrV/3n9ML3uET4dZJFaJO68dC7bjneE1V0UDVsH+lsHW1j3g43c89QOnt56gpSEOLr6h3nlQDP/88YRXqg6FdGeGsF0Dwzz109W0d7n5pG7KinKnHy/7GXFmfzojlUcbnZxz5NVUe8IaIzhqS0nuOVHm2l1ufnv2y7if//2cm5YVsi15QX89RXz+fR7ykhwOHjs7eM8+PrhiK+c829/qEEEvn5jeVRjvnV1KcuKM/jar/eG/AZb3djDf716iJuWF/LBCEsg3/5gBQDfeXH/lMeuf7eREa+xrNwy1icvmUuLyz1arx6v1eVm/d5Gbl1dSnqI+3FPJc+ZxHUVBfxs0/GgXUZtvW5e2d/ELatKwl4hGarPXTGPzv7hSS948sM3j5DvTOIjq0Nb3zARZ3ICX7luEa8eaOa57ZN/GjrW2svjm2v5eOVsLijJnPTYUN152VwW5KXxL+sPhNWmGilbBvqx1l4+8/h27v75drwGfnrnavb+8/U8/zeXcf/7FvPNm5Zy9ZI89tV38/1XD/Lg64ejCtS6zn5u/fFm9tV384OPr2RFaWgfzd+7JJ9//+gKthzr4N5ndkb85tLcM8jfPr2Tf/rtPt6zcBZ/uO9Kbr6o5LQTeCLCogInf3v1Ai6cncX3Xz3E7T/bwvG20HuCAd6oaWb93kY+f9WCiC7yMFZSfBz/84mVDI14ue+53VO+wQwOe/jK87vJTEnkXz68POIZc2l2Kl++dhEbDjTzyKZjE87c3q3r5l/XH+CCkozRK/9Y6eryfEqyUvjZpmNn/P3rdY9w33O7GPF6+eSlkZW1JvJvt6xgVloiX3h6x2l/54wxPPr2cYY9htunodwScMm8HJaXZPLopuNnLDIyxvDdP9aw+Wg791w5f9LN3kL1ubXzWbswlwd+f2DSFcr/ur6a5IQ4vnr9kqifMyAhzsG3PriM2vZ+nthca9nvnUhIgS4i60TkoIgcEZGvB7k/SUSe99+/VUTKrB5oKE629/PA7w9w/X9tZPvxDv7xpqW8cv+V3LCs8LS/GOlJ8VxXUcj971vMkgIn33/1ENf+5594Yfsp+odGQn6+EY+Xl/Y28Fc/2kxTzyBPfGYN68LsRPirlaU8cPMy3jzYyo0/2MjmMBYi9A+N8Njbx7n2P//E6zUt/J915Tx218XkTLKyLyk+jo+uLuV7t67gQGMP636wkYfeOEznFCvafDXNo3zuiSqWFDj5mysXhDzOyczPS+f/3XwB2453cP/zuyc8p/BuXTc3P/RnappcfPcjyyd9jaH47Np5XFdRwL+sr+YffrX3jEA91trL3T/fRlZqIo/edbGl5ZaAOIdw37WL2Hmyi1t+tJkT/gU3nX1D3PHIVrYe7+A/P3Zh1CfnxstJS+Sh21fR2DXIl57dxbbjHbS63Nz77C5+/NZRblpeGNUl56YiItxz5XyOtfVx+yN/mVSMeLz839/u48dvHeX2S+aEdcJ7Mg6H8J8fu5DkBAef/8WOM/ZY6XWP8G9/qOb1mhbuvWYhec7QLh4SqqsW53FteT7//dph1u8NbR1ApKb8HCciccAPgeuAOmC7iLxojDkw5rDPAp3GmIUichvwXeDj0zFg94iH7oFh3MNe3CMeTrT3U9PkYtPhVrYc60AEPl45m69ev2TK/zE5aYncfslc5uWm8cBLB/jar/fywEsHWHdBISvnZFFe6CTfmUxaUjwJccLgsBfX4DBHWno50NjDb3bWc7KjnwV5aTz9uUsiXkX4qcvKuLA0i688v5vbH9nKitJMbljmG0O+M5ns1AQ8XoN7xEtD1wC17X1sPtrOhv3NDAx7uGJRLg/cfAHzctNCej4R4WOVs7lqcR7f+t0+/mPDIR58/QjXVRSwZl4OC/LSyXMm4TWGXvcIVbWdvFHTzPbaTt6/oojvfmRFRJ0tE/nI6lJOdvTzo7eO8NqBZj5+8WwWFzjJcyZxor2Pd+u7eWlvI7npifz87ou5Osye5GAS4x389JOr+cHrh3nw9cO8dbCVS+b7Xvt+/3YCifEOnvrsmqiueD+Vj108m1xnIl95fg/rfrCJ1MQ4OvqHSHA4+PEdq7h+WXStihNZPTebb3+wgm+9uH90E6t4h/C1dUsse7OezAdWFNHnHuFfX67mhh9sZHZ2Cic7+hn2GL7w3gV87YYllr6JFmQk89Dtq7j/+d187KfvcMWiXBYXOPEaw/q9jbS43NyyqsSy2vl437l5Gfc8uYMvPrOTtQtz+c7NyyzvIIIQAh1YAxwxxhwDEJHngJuBsYF+M/DP/u9/BTwkImKm4a1ow/5mvvTsrjNun5+Xxt9fv5hbVpVSHGYp4LIFs3j5y2vZXtvJC1WneGV/U0grzFbPzeabNy3luoqCCfcRCdWFs7NY/+UrePKdWv6wr4l/f+XgpMdnpiTw4ZUl3HxRMZfMy4noL39BRjI/vbOSAw09/HLHKX63u4H1E/QoL8xP5zsfWmZZt8V4X7luMbesKuF7rxzkqS0nTiu/5DuT+FjlbL6+rpzM1MhWSgbjcAh/d91iVs7J4re76tl+vIP1exuZn5fGjcsL+eza+cyfhn90411TXsBLX1rLD988gsMh5KYncU15vqVdNcHceVkZH1hRzPbaDvbVd/O+ioKQy4XREhFuWzOHa8rz+Y8NB+keGOb6ZYWsmpPNdRXhrWsI1eULc9n4D1fz1JZafv7nWnad9HW+lBc6+cmdqyNe5h+K0uxUXrz3cp7eepL/2HCQ57ad5B/fX2H588hUmSsitwLrjDGf8/98J3CJMebeMcfs8x9T5//5qP+YtnG/6x7gHv+PS4DJU8tecgF7LBENz/n4uvU1nx9i9ZrnGmOCLmMNZYYebDo2/l0glGMwxjwMPBzCc9qOiFQZYypjPY6Zdj6+bn3N54ez8TWHclK0Dhi7lV0pML6JdfQYEYkHMoGZ391dKaXOY6EE+nZgkYjME5FE4DbgxXHHvAjc5f/+VuCN6aifK6WUmtiUJRdjzIiI3Au8AsQBjxlj9ovIA0CVMeZF4FHgKRE5gm9mftt0DvocdV6Wmjg/X7e+5vPDWfeapzwpqpRS6txgy5WiSil1PtJAV0opm9BAn2Yi8piItPh79c8LIjJbRN4UkWoR2S8i98V6TDNBRJJFZJuI7PG/7u/EekwzQUTiRGSXiLwU67HMFBGpFZF3RWS3iFTFejwBWkOfZiJyJdALPGmMuSDW45kJIlIEFBljdoqIE9gBfHjcdhG2I74ltGnGmF4RSQDeBu4zxmyJ8dCmlYj8HVAJZBhjPhDr8cwEEakFKscvnow1naFPM2PMRs6znnxjTKMxZqf/exdQDUS3D+o5wPgEtvNL8H/ZesYkIqXA+4FHYj0WpYGuppl/582VwNbYjmRm+MsPu4EW4FVjjN1f9w+ArwHWXArr3GGADSKyw7+lyVlBA11NGxFJB34N3G+MCf1S7+cwY4zHGHMRvhXVa0TEtmU2EfkA0GKM2RHrscTA5caYVcCNwBf9pdWY00BX08JfQ/418LQx5jexHs9MM8Z0AW8B62I8lOl0OfAhfz35OeAaEflFbIc0M4wxDf7/tgD/i29X2pjTQFeW858cfBSoNsZ8P9bjmSkikiciWf7vU4D3ATWxHdX0McZ8wxhTaowpw7c6/A1jzCdjPKxpJyJp/pP9iEgacD1wVnSxaaBPMxF5FngHWCIidSLy2ViPaQZcDtyJb8a22/91U6wHNQOKgDdFZC++PZBeNcacN61855EC4G0R2QNsA9YbY/4Y4zEB2raolFK2oTN0pZSyCQ10pZSyCQ10pZSyCQ10pZSyCQ10pZSyCQ10pQARuV9EUsf8/HKgp1ypc4W2Larzhn/Bkxhjzth35GzdPU+pcOgMXdmaiJT592X/EbATeFREqsbuVy4iXwaK8S0KetN/W62I5I55/M/8j9ngXwWKiFwsIntF5B0R+ffzac97dXbSQFfngyX49qNfCXzVGFMJrACuEpEVxpgHgQbgamPM1UEevwj4oTFmGdAFfMR/+8+BzxtjLgM80/4qlJqCBro6H5wYc5GJj4nITmAXsAyoCOHxx40xu/3f7wDK/PV1pzFms//2ZywdsVIRiI/1AJSaAX0AIjIP+HvgYmNMp4g8DiSH8Hj3mO89QAogVg9SqWjpDF2dTzLwhXu3iBTg28s6wAU4Q/1FxphOwCUil/pvus2yUSoVIZ2hq/OGMWaPiOwC9gPHgD+Pufth4A8i0jhBHT2YzwI/E5E+fHufd1s5XqXCpW2LSkVIRNID1xAVka/juzD2fTEeljqP6Qxdqci9X0S+ge/f0Qng7tgOR53vdIaulFI2oSdFlVLKJjTQlVLKJjTQlVLKJjTQlVLKJjTQlVLKJv4/BR904RHZFTMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(ratings_df['rating'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습 데이터, 하이퍼 파라미터 initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 유저-아이템의 Rating 매트릭스\n",
    "user_item_matrix = ratings_df.pivot_table(\"rating\", \"userId\", 'movieId').fillna(0)\n",
    "\n",
    "# numpy 형태로 변환\n",
    "R = user_item_matrix.to_numpy()\n",
    "\n",
    "# 잠재 요인의 수\n",
    "K = 20\n",
    "learning_rate = 0.01\n",
    "\n",
    "# l2 정규화 파라미터\n",
    "regularization = 0.2\n",
    "\n",
    "# 학습 데이터의 반복 횟수\n",
    "iterations = 20\n",
    "\n",
    "num_users, num_items = user_item_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습 파라미터 initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평균이 0, 표준편차는 1/K로 랜덤하게 initialize\n",
    "P = np.random.normal(scale = 1./K, size=(num_users, K))\n",
    "Q = np.random.normal(scale = 1./K, size=(num_items, K))\n",
    "\n",
    "# Initialize the biases\n",
    "# 유저별 bias\n",
    "b_u = np.zeros(num_users)\n",
    "\n",
    "# 아이템별 bias\n",
    "b_i = np.zeros(num_items)\n",
    "\n",
    "# 전체 bias\n",
    "b = np.mean(R[np.where(R != 0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(610, 9724)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습 데이터 구성\n",
    "- 실제 평가를 내린 데이터만 학습에 사용함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = [(i, j, R[i, j]) for i in range(num_users) for j in range(num_items) if R[i, j] > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 총 학습 데이터 사이즈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100836"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD를 활용한 파라미터 업데이트"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Parameter Update\n",
    "![ab](https://i.ibb.co/QCgV5Ys/svd-sgd.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.8985076095560088\n",
      "2 0.8767818798319986\n",
      "3 0.8646634286524926\n",
      "4 0.8574577657899166\n",
      "5 0.8512418143350183\n",
      "6 0.8464153437723833\n",
      "7 0.8437287263911325\n",
      "8 0.8401694267334513\n",
      "9 0.8378809686168452\n",
      "10 0.8348362479769528\n",
      "11 0.8328189670186613\n",
      "12 0.831432361999392\n",
      "13 0.8287099317241761\n",
      "14 0.8282899406788337\n",
      "15 0.8263952894590282\n",
      "16 0.8244698706894156\n",
      "17 0.8236359103608241\n",
      "18 0.8232049663362809\n",
      "19 0.8212657765542805\n",
      "20 0.8207961066513243\n"
     ]
    }
   ],
   "source": [
    "training_result = []\n",
    "\n",
    "for epoch in range(iterations):\n",
    "    \n",
    "    # 학습 데이터 순서를 셔플링\n",
    "    np.random.shuffle(samples)\n",
    "    \n",
    "    for i, j, r in samples:\n",
    "        \n",
    "        # 현재 주어진 파라미터로 predicted rating을 구함\n",
    "        prediction = b + b_u[i] + b_i[j] + P[i, :].dot(Q[j, :].T)\n",
    "        \n",
    "        # 실제 rating과 predicted rating의 차이가 error\n",
    "        e = (r - prediction)\n",
    "        \n",
    "        # 유저, 아이템 bias 파라미터를 업데이트\n",
    "        b_u[i] += learning_rate * (e - regularization * b_u[i])\n",
    "        b_i[j] += learning_rate * (e - regularization * b_i[j])\n",
    "        \n",
    "        # 유저, 아이템 잠재 행렬 파라미터를 업데이트\n",
    "        P[i, :] += learning_rate * (e * Q[j, :] - regularization * P[i, :])\n",
    "        Q[j, :] += learning_rate * (e * P[i, :] - regularization * Q[j, :])\n",
    "        \n",
    "    # 학습이 모두 끝나고 학습 데이터를 활용해 training loss를 구합니다.\n",
    "    ut, it = R.nonzero()\n",
    "    predicted_R = b + b_u[:, np.newaxis] + b_i[np.newaxis, :] + P.dot(Q.T) # add new axis, dimension 1 => 2\n",
    "    error = []\n",
    "    \n",
    "    for x, y in zip(ut, it):\n",
    "        error.append(pow(R[x, y] - predicted_R[x, y], 2))\n",
    "    rmse = np.sqrt(np.asarray(error).mean())\n",
    "    print(epoch + 1, rmse)\n",
    "    training_result.append([epoch + 1, rmse])\n",
    "    \n",
    "traing_result_pd = pd.DataFrame(training_result, columns = ['iteration', 'rmse'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02. MF with Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 위에서 구한 MF를 SGD로 학습하는 것을 class 형태로 만듦\n",
    "\n",
    "class MF():\n",
    "\n",
    "    def __init__(self, R, K, learning_rate, regularization, iterations):\n",
    "        \"\"\"\n",
    "        Arguments\n",
    "        - R (ndarray)             : 유저 아이템 매트릭스\n",
    "        - K (int)                 : latent factor 차원\n",
    "        - learning_rate (float)   : learning rate\n",
    "        - regularization (float)  : regularization parameter\n",
    "        \"\"\"\n",
    "        self.R = R\n",
    "        self.num_users, self.num_items = R.shape\n",
    "        self.K = K\n",
    "        self.learning_rate = learning_rate\n",
    "        self.regularization = regularization\n",
    "        self.iterations = iterations\n",
    "\n",
    "    def train(self):\n",
    "        \n",
    "        # 유저, 아이템 잠재 요인 행렬 초기화\n",
    "        self.P = np.random.normal(scale=1./self.K, size=(self.num_users, self.K))\n",
    "        self.Q = np.random.normal(scale=1./self.K, size=(self.num_items, self.K))\n",
    "\n",
    "        # 유저, 아이템, 글로벌 bias 초기화\n",
    "        self.b_u = np.zeros(self.num_users)\n",
    "        self.b_i = np.zeros(self.num_items)\n",
    "        self.b = np.mean(self.R[np.where(self.R != 0)])\n",
    "\n",
    "        # 학습 데이터 생성\n",
    "        self.samples = [\n",
    "            (i, j, self.R[i, j])\n",
    "            for i in range(self.num_users)\n",
    "            for j in range(self.num_items)\n",
    "            if self.R[i, j] > 0\n",
    "        ]\n",
    "\n",
    "        # iteration 개수만큼 전체 데이터에 대해서 SGD 수행\n",
    "        training_process = []\n",
    "        for i in range(self.iterations):\n",
    "            np.random.shuffle(self.samples)\n",
    "            self.sgd()\n",
    "            rmse = self.rmse()\n",
    "            training_process.append((i, rmse))\n",
    "            if (i+1) % 10 == 0:\n",
    "                print(\"Iteration: %d, error = %.4f\" % (i+1, rmse))\n",
    "\n",
    "        return pd.DataFrame(training_process, columns = ['iteration', 'rmse'])\n",
    "\n",
    "    def rmse(self):\n",
    "        \"\"\"\n",
    "        전체 학습 데이터에 대한 rmse 계산\n",
    "        \"\"\"\n",
    "        ut, it = self.R.nonzero()\n",
    "        predicted_R = self.full_matrix()\n",
    "        error = []\n",
    "        for x, y in zip(ut, it):\n",
    "            error.append(pow(R[x, y] - predicted_R[x, y], 2))\n",
    "        return np.sqrt(np.asarray(error).mean())\n",
    "\n",
    "    def sgd(self):\n",
    "        \"\"\"\n",
    "        sgd로 파라미터 업데이트가 되는 함수\n",
    "        \"\"\"\n",
    "        for i, j, r in self.samples:\n",
    "            # 실제 rating과 predicted rating을 구하고 error를 구함\n",
    "            prediction = self.get_rating(i, j)\n",
    "            e = (r - prediction)\n",
    "\n",
    "            # bias 업데이트\n",
    "            self.b_u[i] += self.learning_rate * (e - self.regularization * self.b_u[i])\n",
    "            self.b_i[j] += self.learning_rate * (e - self.regularization * self.b_i[j])\n",
    "\n",
    "            # 유저, 아이템 잠재 요인 행렬 업데이트\n",
    "            self.P[i, :] += self.learning_rate * (e * self.Q[j, :] - self.regularization * self.P[i,:])\n",
    "            self.Q[j, :] += self.learning_rate * (e * self.P[i, :] - self.regularization * self.Q[j,:])\n",
    "\n",
    "    def get_rating(self, i, j):\n",
    "        \"\"\"\n",
    "        유저 i, 아이템 j에 대한 예측 평점\n",
    "        \"\"\"\n",
    "        prediction = self.b + self.b_u[i] + self.b_i[j] + self.P[i, :].dot(self.Q[j, :].T)\n",
    "        return prediction\n",
    "\n",
    "    def full_matrix(self):\n",
    "        \"\"\"\n",
    "        예측된 유저 아이템 매트릭스를 계산 Rhat\n",
    "        \"\"\"\n",
    "        return self.b + self.b_u[:,np.newaxis] + self.b_i[np.newaxis:,] + self.P.dot(self.Q.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 주어진 유저-아이템 매트릭스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = np.array([\n",
    "    [5, 3, 0, 1],\n",
    "    [4, 0, 0, 1],\n",
    "    [1, 1, 0, 5],\n",
    "    [1, 0, 0, 4],\n",
    "    [0, 1, 5, 4],\n",
    "])\n",
    "\n",
    "mf = MF(R, K=2, learning_rate=0.1, regularization=0.01, iterations=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MF 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 10, error = 0.0691\n",
      "Iteration: 20, error = 0.0128\n",
      "Iteration: 30, error = 0.0104\n"
     ]
    }
   ],
   "source": [
    "train_result_df = mf.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 예측 매트릭스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.98216574, 3.00148616, 3.12893148, 1.01203491],\n",
       "       [3.99472109, 2.39797629, 2.72437338, 1.01210592],\n",
       "       [1.00763819, 1.00567955, 4.98663646, 4.98650283],\n",
       "       [1.00864123, 1.15959422, 3.84891291, 3.99471856],\n",
       "       [1.96237706, 1.0159439 , 4.98871176, 3.99853666]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mf.full_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03. 무비렌즈 데이터로 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_item_matrix = ratings_df.pivot_table('rating', 'userId', 'movieId').fillna(0)\n",
    "R = user_item_matrix.to_numpy()\n",
    "K = 20\n",
    "learning_rate = 0.01\n",
    "regularization = 0.2\n",
    "\n",
    "mf = MF(R, K, learning_rate, regularization, iterations=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 10, error = 0.8351\n",
      "Iteration: 20, error = 0.8202\n",
      "Iteration: 30, error = 0.8131\n"
     ]
    }
   ],
   "source": [
    "train_result_df = mf.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# iteration에 따른 training loss\n",
    "\n",
    "x = train_result_df.iteration.values + 1\n",
    "y = train_result_df.rmse.values\n",
    "plt.figure(figsize=((8,4)))\n",
    "plt.plot(x, y)\n",
    "plt.xticks(x, x)\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"RMSE\")\n",
    "plt.grid(axis=\"y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 04. Matrix Factorization의 ALS 구현\n",
    "1. 초기 사용자, 아이템 행렬을 초기화\n",
    "2. 아이템 행렬을 고정하고 사용자 행렬을 최적화\n",
    "3. 사용자 행렬을 고정하고 아이템 행렬을 최적화\n",
    "4. 2, 3의 과정을 반복"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 유저-아이템 행렬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = np.array([\n",
    "        [1, 0, 0, 1, 3],\n",
    "        [2, 0, 3, 1, 1],\n",
    "        [1, 2, 0, 5, 0],\n",
    "        [1, 0, 0, 4, 4],\n",
    "        [2, 1, 5, 4, 0],\n",
    "        [5, 1, 5, 4, 0],\n",
    "        [0, 0, 0, 1, 0], ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습 데이터, 하이퍼 파라미터 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 잠재요인 개수\n",
    "k = 5\n",
    "\n",
    "# l2 하이퍼파라미터\n",
    "regularization = 0.01\n",
    "\n",
    "num_users, num_items = R.shape\n",
    "\n",
    "# ALS 업데이트 횟수 - SGD보다 많다\n",
    "iterations = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 유저, 아이템 잠재요인 매트릭스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = np.random.normal(scale=1./k, size=(num_users, k))\n",
    "items = np.random.normal(scale=1./k, size=(num_items, k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 5)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ALS 업데이트 수식\n",
    "![수식](https://i.ibb.co/Csh6Yb0/2021-06-25-10-50-03.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### iteration마다 위에 있는 수식을 활용해 유저, 아이템을 업데이트 한다.\n",
    "[참고](https://numpy.org/doc/stable/reference/generated/numpy.linalg.solve.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 10, cost = 0.0012\n",
      "Iteration: 20, cost = 0.0014\n",
      "Iteration: 30, cost = 0.0015\n",
      "Iteration: 40, cost = 0.0017\n",
      "Iteration: 50, cost = 0.0019\n",
      "Iteration: 60, cost = 0.0020\n",
      "Iteration: 70, cost = 0.0021\n",
      "Iteration: 80, cost = 0.0023\n",
      "Iteration: 90, cost = 0.0024\n",
      "Iteration: 100, cost = 0.0025\n"
     ]
    }
   ],
   "source": [
    "training_process = []\n",
    "\n",
    "for epoch in range(iterations):\n",
    "    for i, Ri in enumerate(R):\n",
    "        users[i] = np.linalg.solve(np.dot(items.T, items) + regularization * np.eye(k), \\\n",
    "                                  np.dot(items.T, R[i].T)).T\n",
    "        \n",
    "    for j, Rj in enumerate(R.T):\n",
    "        items[j] = np.linalg.solve(np.dot(users.T, users) + regularization * np.eye(k), \\\n",
    "                                  np.dot(users.T, R[:, j]))\n",
    "        \n",
    "    cost = 0\n",
    "    xi, yi = R.nonzero()\n",
    "    \n",
    "    for x, y in zip(xi, yi):\n",
    "        cost += pow(R[x, y] - users[x, :].dot(items[y, :].T), 2)\n",
    "        \n",
    "    cost = np.sqrt(cost / len(xi))\n",
    "    training_process.append((epoch, cost))\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(\"Iteration: %d, cost = %.4f\" % (epoch+1, cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 1, 3],\n",
       "       [2, 0, 3, 1, 1],\n",
       "       [1, 2, 0, 5, 0],\n",
       "       [1, 0, 0, 4, 4],\n",
       "       [2, 1, 5, 4, 0],\n",
       "       [5, 1, 5, 4, 0],\n",
       "       [0, 0, 0, 1, 0]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9.98975638e-01, -4.69085255e-03, -9.39086723e-07,\n",
       "         1.00240683e+00,  2.99618917e+00],\n",
       "       [ 1.99991549e+00, -9.89489528e-04,  2.99831551e+00,\n",
       "         1.00142440e+00,  9.98392956e-01],\n",
       "       [ 9.99889331e-01,  1.99527754e+00,  1.76498836e-03,\n",
       "         4.99844281e+00,  9.11066701e-04],\n",
       "       [ 1.00061424e+00,  4.51013653e-03,  6.62001072e-04,\n",
       "         3.99749804e+00,  3.99837385e+00],\n",
       "       [ 2.00470453e+00,  9.99196095e-01,  4.99602129e+00,\n",
       "         3.99901825e+00, -4.19181670e-04],\n",
       "       [ 4.99483720e+00,  1.00156207e+00,  5.00127110e+00,\n",
       "         4.00001202e+00,  1.57554721e-03],\n",
       "       [ 3.31383008e-04,  4.13530988e-03,  4.67461959e-04,\n",
       "         9.97899755e-01,  1.37872304e-03]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R_hat = users.dot(items.T)\n",
    "R_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 05. ALS 클래스 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "class AlternatingLeastSquares():\n",
    "    def __init__(self, R, k, regularization, iterations, verbose=False):\n",
    "        \"\"\"\n",
    "        Arguments\n",
    "        - R (ndarray)             : 유저 아이템 매트릭스\n",
    "        - k (int)                 : latent factor 차원\n",
    "        - reg_param (float)       : regularization parameter\n",
    "        - epochs (int)            : als로 파라미터 업데이트를 수행하는 횟수\n",
    "        - verbose (boolean)       : 학습 과정의 status print 옵션\n",
    "        \"\"\"\n",
    "        self.R = R\n",
    "        self.num_users, self.num_items = R.shape\n",
    "        self.k = k\n",
    "        self.regularization = regularization\n",
    "        self.iterations = iterations\n",
    "        self.verbose = verbose\n",
    "\n",
    "\n",
    "    def fit(self):\n",
    "\n",
    "        # 유저, 아이템 매트릭스를 초기화\n",
    "        self.users = np.random.normal(scale=1./k, size=(self.num_users, self.k))\n",
    "        self.items = np.random.normal(scale=1./k, size=(self.num_items, self.k))\n",
    "\n",
    "        # iteration 개수만큼 ALS를 수행하여 유저, 아이템 파라미터를 업데이트함\n",
    "        self._training_process = [] \n",
    "        for iteration in range(self.iterations):\n",
    "            for i, Ri in enumerate(self.R):\n",
    "                self.users[i] = self.user_latent(i, Ri)\n",
    "\n",
    "            for j, Rj in enumerate(self.R.T):\n",
    "                self.items[j] = self.item_latent(j, Rj)\n",
    "            \n",
    "            # iteration 수행이 끝날때마다 training loss를 계산함\n",
    "            cost = self.cost()\n",
    "            self._training_process.append((iteration, cost))\n",
    "\n",
    "            # 10번째마다 loss를 출력하는 옵션\n",
    "            if self.verbose == True and ((iteration + 1) % 10 == 0):\n",
    "                print(\"Iteration: %d, cost = %.4f\" % (iteration + 1, cost))\n",
    "\n",
    "    def cost(self):\n",
    "        \"\"\"\n",
    "        학습 데이터 전체의 rmse 계산\n",
    "        \"\"\"\n",
    "        xi, yi = self.R.nonzero()\n",
    "        cost = 0\n",
    "        for x, y in zip(xi, yi):\n",
    "            cost += pow(self.R[x, y] - self.get_prediction(x, y), 2)\n",
    "        return np.sqrt(cost/len(xi))\n",
    "\n",
    "\n",
    "    def user_latent(self, i, Ri):\n",
    "        \"\"\"\n",
    "        유저 i에 대한 유저 벡터 업데이트\n",
    "        \"\"\"\n",
    "\n",
    "        du = np.linalg.solve(np.dot(self.items.T, self.items) + self.regularization * np.eye(self.k),\n",
    "                                   np.dot(self.items.T, self.R[i].T)).T\n",
    "        return du\n",
    "\n",
    "    def item_latent(self, j, Rj):\n",
    "        \"\"\"\n",
    "        아이템 j에 대한 아이템 벡터 업데이트\n",
    "        \"\"\"\n",
    "\n",
    "        di = np.linalg.solve(np.dot(self.users.T, self.users) + self.regularization * np.eye(self.k),\n",
    "                                 np.dot(self.users.T, self.R[:, j]))\n",
    "        return di\n",
    "\n",
    "\n",
    "    def get_prediction(self, i, j):\n",
    "        \"\"\"\n",
    "        유저 i, 아이템 j에 대한 예측 평점\n",
    "        \"\"\"\n",
    "        return self.users[i, :].dot(self.items[j, :].T)\n",
    "\n",
    "\n",
    "    def get_full_matrix(self):\n",
    "        \"\"\"\n",
    "        예측된 유저 아이템 매트릭스를 계산 Rhat\n",
    "        \"\"\"\n",
    "        return self.users.dot(self.items.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 10, cost = 0.0009\n",
      "Iteration: 20, cost = 0.0012\n"
     ]
    }
   ],
   "source": [
    "R = np.array([\n",
    "        [1, 0, 0, 1, 3],\n",
    "        [2, 0, 3, 1, 1],\n",
    "        [1, 2, 0, 5, 0],\n",
    "        [1, 0, 0, 4, 4],\n",
    "        [2, 1, 5, 4, 0],\n",
    "        [5, 1, 5, 4, 0],\n",
    "        [0, 0, 0, 1, 0],\n",
    "    ])\n",
    "\n",
    "als = AlternatingLeastSquares(R = R, regularization = 0.01, iterations=20, verbose=True, k=5)\n",
    "als.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.00054010e+00, -3.47877765e-03, -3.07850656e-05,\n",
       "         1.00145857e+00,  2.99780665e+00],\n",
       "       [ 2.00031893e+00, -9.63067626e-04,  2.99943684e+00,\n",
       "         1.00064909e+00,  9.99116778e-01],\n",
       "       [ 1.00022716e+00,  1.99745563e+00,  6.02141466e-04,\n",
       "         5.00002898e+00, -3.05200754e-04],\n",
       "       [ 9.99870035e-01,  2.83436033e-03,  1.87015227e-04,\n",
       "         3.99878779e+00,  4.00031825e+00],\n",
       "       [ 2.00187426e+00,  9.99325083e-01,  4.99864343e+00,\n",
       "         3.99992359e+00, -8.74636355e-04],\n",
       "       [ 4.99783945e+00,  1.00132656e+00,  5.00052129e+00,\n",
       "         3.99968444e+00,  1.42307860e-03],\n",
       "       [-4.86904306e-04,  2.88566877e-03,  1.63767264e-04,\n",
       "         9.98806174e-01,  1.31175866e-03]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "als.get_full_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0006490940803254"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "als.get_prediction(1, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 06. Surprise에서 제공하는 MF 모델(SVD)\n",
    "- Surprise 패키지의 SVD는 SGD로 학습되는 MF를 의미한다.\n",
    "- SGD로 모델이 학습될 대 변경 가능한 옵션과 하이퍼파라미터에 대해 살펴본다.\n",
    "- 무비렌즈 데이터를 활용해 kNN 모델과 SVD 모델을 각각 학습해보고 추천 성능을 비교해본다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# surprise에서 제공하는 dataset과 reader\n",
    "\n",
    "from surprise import Reader, Dataset\n",
    "\n",
    "reader = Reader(rating_scale=(0.5, 5.0))\n",
    "data = Dataset.load_from_df(ratings_df[['userId', 'movieId', 'rating']], reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import accuracy\n",
    "from surprise.model_selection import train_test_split\n",
    "\n",
    "# train / test 데이터 나누기\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVD Model\n",
    "\n",
    "- [모델 API 문서](https://surprise.readthedocs.io/en/stable/matrix_factorization.html)\n",
    "- The SVD++ algorithm, an extension of SVD taking into account implicit ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.8660\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8660030808698003"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SVD 모델을 사용하자 => MF의 SGD 구현을 Suprise에서 SVD로 부름\n",
    "\n",
    "svd_model = SVD(n_factors=20, reg_all = 0.02)\n",
    "\n",
    "# 학습데이터를 가지고 모델 학습\n",
    "svd_model.fit(train_data)\n",
    "\n",
    "# 테스트 데이터로 모델의 예측 평점을 추론\n",
    "predictions = svd_model.test(test_data)\n",
    "\n",
    "# Then compute RMSE\n",
    "accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 유저/아이템 매트릭스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(610, 20)\n",
      "(8933, 20)\n"
     ]
    }
   ],
   "source": [
    "print(svd_model.pu.shape)\n",
    "print(svd_model.qi.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 유저 0의 latent factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.03099873, -0.05642505, -0.07785974, -0.16784845, -0.10577581,\n",
       "        0.05834872,  0.07545349, -0.02610836, -0.00734263,  0.12959561,\n",
       "       -0.15351897,  0.06536194,  0.08620424,  0.1744412 , -0.05833897,\n",
       "       -0.20289811,  0.20321874, -0.3789021 , -0.15915271, -0.01673731])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd_model.pu[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 아이템 0의 latent factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.25599293, -0.24280786,  0.00535914,  0.09900458, -0.13744529,\n",
       "       -0.23939816,  0.02116269, -0.04442159,  0.27611131,  0.18141644,\n",
       "       -0.08812498, -0.1745348 ,  0.03973557,  0.28163829, -0.21130212,\n",
       "       -0.06865931, -0.2036131 ,  0.27009727, -0.0720132 ,  0.03788732])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd_model.qi[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 평점 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(uid=1, iid=1, r_ui=None, est=4.611782498381671, details={'was_impossible': False})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_id = 1\n",
    "item_id = 1\n",
    "\n",
    "svd_model.predict(user_id, item_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 새로운 유저, 아이템이 등장할 경우 default_prediction을 사용\n",
    "![default_prediction](https://i.ibb.co/6YxrX1s/default-prediction.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5001859473397134\n",
      "3.5001859473397134\n"
     ]
    }
   ],
   "source": [
    "user_id = 0\n",
    "item_id = 0\n",
    "\n",
    "print(svd_model.predict(user_id, item_id).est)\n",
    "print(svd_model.default_prediction())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [모델 상세 옵션](https://surprise.readthedocs.io/en/stable/matrix_factorization.html#surprise.prediction_algorithms.matrix_factorization.SVD)\n",
    "\n",
    "- Rating Function\n",
    "![ab](https://i.ibb.co/MSZJKLp/svd-rating.png)\n",
    "- Objective Function\n",
    "![ab](https://i.ibb.co/DzMmtyx/svd-obj.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### bias 유무에 따른 성능 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9852\n",
      "biased: False , 0.985227512074916\n",
      "RMSE: 0.8704\n",
      "biased: True , 0.8703636789383212\n"
     ]
    }
   ],
   "source": [
    "for biased in [False, True]:\n",
    "    svd_model = SVD(biased=biased)\n",
    "    svd_model.fit(train_data)\n",
    "    predictions = svd_model.test(test_data)\n",
    "\n",
    "    # Then compute RMSE\n",
    "    print('biased:', biased, ',', accuracy.rmse(predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### latent factor 수에 따른 성능 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.8669\n",
      "n_factors: 25 , 0.866884038010784\n",
      "RMSE: 0.8680\n",
      "n_factors: 50 , 0.8680162935758132\n",
      "RMSE: 0.8726\n",
      "n_factors: 100 , 0.8725720245049245\n",
      "RMSE: 0.8747\n",
      "n_factors: 150 , 0.8747062420938684\n"
     ]
    }
   ],
   "source": [
    "for k in [25, 50, 100, 150]:\n",
    "    svd_model = SVD(n_factors=k)\n",
    "    svd_model.fit(train_data)\n",
    "    predictions = svd_model.test(test_data)\n",
    "\n",
    "    # Then compute RMSE\n",
    "    print('n_factors:', k, ',', accuracy.rmse(predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### learning rate에 따른 성능 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.8776\n",
      "lr_all: 0.0025 , 0.8776344461608272\n",
      "RMSE: 0.8699\n",
      "lr_all: 0.005 , 0.8699222480341662\n",
      "RMSE: 0.8951\n",
      "lr_all: 0.001 , 0.8950513514160988\n"
     ]
    }
   ],
   "source": [
    "for lr_all in [.0025, .005, .001]:\n",
    "    svd_model = SVD(lr_all=lr_all)\n",
    "    svd_model.fit(train_data)\n",
    "    predictions = svd_model.test(test_data)\n",
    "\n",
    "    # Then compute RMSE\n",
    "    print('lr_all:', lr_all, ',', accuracy.rmse(predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### regularization에 따른 성능 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.8937\n",
      "reg_all: 0 , 0.8936555235686122\n",
      "RMSE: 0.8704\n",
      "reg_all: 0.02 , 0.870430014866698\n",
      "RMSE: 0.8673\n",
      "reg_all: 0.1 , 0.8673302158459903\n",
      "RMSE: 0.9051\n",
      "reg_all: 1 , 0.905099471006505\n"
     ]
    }
   ],
   "source": [
    "for reg_all in [0, 0.02, 0.1, 1]:\n",
    "    svd_model = SVD(reg_all=reg_all)\n",
    "    svd_model.fit(train_data)\n",
    "    predictions = svd_model.test(test_data)\n",
    "\n",
    "    # Then compute RMSE\n",
    "    print('reg_all:', reg_all, ',', accuracy.rmse(predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Search 패키지를 제공함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise.model_selection import GridSearchCV\n",
    "\n",
    "grid = {'lr_all': [.0025, .005], \n",
    "        'n_factors': [25, 50, 100],\n",
    "        'reg_all': [0.02, 0.1]\n",
    "       }\n",
    "\n",
    "gs = GridSearchCV(SVD, grid, measures=['RMSE'], cv=2)\n",
    "gs.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>split0_test_rmse</th>\n",
       "      <th>split1_test_rmse</th>\n",
       "      <th>mean_test_rmse</th>\n",
       "      <th>std_test_rmse</th>\n",
       "      <th>rank_test_rmse</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_test_time</th>\n",
       "      <th>std_test_time</th>\n",
       "      <th>params</th>\n",
       "      <th>param_lr_all</th>\n",
       "      <th>param_n_factors</th>\n",
       "      <th>param_reg_all</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.879590</td>\n",
       "      <td>0.881011</td>\n",
       "      <td>0.880301</td>\n",
       "      <td>0.000711</td>\n",
       "      <td>1</td>\n",
       "      <td>2.306833</td>\n",
       "      <td>0.004266</td>\n",
       "      <td>0.677244</td>\n",
       "      <td>0.006639</td>\n",
       "      <td>{'lr_all': 0.005, 'n_factors': 25, 'reg_all': ...</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>25</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.880503</td>\n",
       "      <td>0.881280</td>\n",
       "      <td>0.880891</td>\n",
       "      <td>0.000388</td>\n",
       "      <td>2</td>\n",
       "      <td>3.600934</td>\n",
       "      <td>0.186163</td>\n",
       "      <td>0.794973</td>\n",
       "      <td>0.108060</td>\n",
       "      <td>{'lr_all': 0.005, 'n_factors': 50, 'reg_all': ...</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>50</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.881055</td>\n",
       "      <td>0.881315</td>\n",
       "      <td>0.881185</td>\n",
       "      <td>0.000130</td>\n",
       "      <td>3</td>\n",
       "      <td>5.557814</td>\n",
       "      <td>0.045481</td>\n",
       "      <td>0.668756</td>\n",
       "      <td>0.000647</td>\n",
       "      <td>{'lr_all': 0.005, 'n_factors': 100, 'reg_all':...</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>100</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.880162</td>\n",
       "      <td>0.882769</td>\n",
       "      <td>0.881466</td>\n",
       "      <td>0.001303</td>\n",
       "      <td>4</td>\n",
       "      <td>2.374165</td>\n",
       "      <td>0.014508</td>\n",
       "      <td>0.647510</td>\n",
       "      <td>0.003196</td>\n",
       "      <td>{'lr_all': 0.005, 'n_factors': 25, 'reg_all': ...</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>25</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.883886</td>\n",
       "      <td>0.884087</td>\n",
       "      <td>0.883987</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>5</td>\n",
       "      <td>3.371479</td>\n",
       "      <td>0.032349</td>\n",
       "      <td>0.616422</td>\n",
       "      <td>0.041925</td>\n",
       "      <td>{'lr_all': 0.005, 'n_factors': 50, 'reg_all': ...</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>50</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.888658</td>\n",
       "      <td>0.888974</td>\n",
       "      <td>0.888816</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>6</td>\n",
       "      <td>2.346534</td>\n",
       "      <td>0.043830</td>\n",
       "      <td>0.689923</td>\n",
       "      <td>0.001761</td>\n",
       "      <td>{'lr_all': 0.0025, 'n_factors': 25, 'reg_all':...</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>25</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.888655</td>\n",
       "      <td>0.889426</td>\n",
       "      <td>0.889040</td>\n",
       "      <td>0.000385</td>\n",
       "      <td>7</td>\n",
       "      <td>6.030160</td>\n",
       "      <td>0.482804</td>\n",
       "      <td>0.688143</td>\n",
       "      <td>0.007303</td>\n",
       "      <td>{'lr_all': 0.005, 'n_factors': 100, 'reg_all':...</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>100</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.889274</td>\n",
       "      <td>0.889322</td>\n",
       "      <td>0.889298</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>8</td>\n",
       "      <td>2.389229</td>\n",
       "      <td>0.070999</td>\n",
       "      <td>0.741644</td>\n",
       "      <td>0.064878</td>\n",
       "      <td>{'lr_all': 0.0025, 'n_factors': 25, 'reg_all':...</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>25</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.889744</td>\n",
       "      <td>0.889641</td>\n",
       "      <td>0.889693</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>9</td>\n",
       "      <td>3.436527</td>\n",
       "      <td>0.006205</td>\n",
       "      <td>0.665408</td>\n",
       "      <td>0.009951</td>\n",
       "      <td>{'lr_all': 0.0025, 'n_factors': 50, 'reg_all':...</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>50</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.890260</td>\n",
       "      <td>0.890628</td>\n",
       "      <td>0.890444</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>10</td>\n",
       "      <td>5.602694</td>\n",
       "      <td>0.062305</td>\n",
       "      <td>0.668211</td>\n",
       "      <td>0.001114</td>\n",
       "      <td>{'lr_all': 0.0025, 'n_factors': 100, 'reg_all'...</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>100</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.889909</td>\n",
       "      <td>0.891018</td>\n",
       "      <td>0.890464</td>\n",
       "      <td>0.000555</td>\n",
       "      <td>11</td>\n",
       "      <td>3.515481</td>\n",
       "      <td>0.090130</td>\n",
       "      <td>0.670033</td>\n",
       "      <td>0.023949</td>\n",
       "      <td>{'lr_all': 0.0025, 'n_factors': 50, 'reg_all':...</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>50</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.893434</td>\n",
       "      <td>0.893515</td>\n",
       "      <td>0.893474</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>12</td>\n",
       "      <td>6.183955</td>\n",
       "      <td>0.192634</td>\n",
       "      <td>0.824757</td>\n",
       "      <td>0.111739</td>\n",
       "      <td>{'lr_all': 0.0025, 'n_factors': 100, 'reg_all'...</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>100</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    split0_test_rmse  split1_test_rmse  mean_test_rmse  std_test_rmse  \\\n",
       "7           0.879590          0.881011        0.880301       0.000711   \n",
       "9           0.880503          0.881280        0.880891       0.000388   \n",
       "11          0.881055          0.881315        0.881185       0.000130   \n",
       "6           0.880162          0.882769        0.881466       0.001303   \n",
       "8           0.883886          0.884087        0.883987       0.000101   \n",
       "0           0.888658          0.888974        0.888816       0.000158   \n",
       "10          0.888655          0.889426        0.889040       0.000385   \n",
       "1           0.889274          0.889322        0.889298       0.000024   \n",
       "3           0.889744          0.889641        0.889693       0.000052   \n",
       "5           0.890260          0.890628        0.890444       0.000184   \n",
       "2           0.889909          0.891018        0.890464       0.000555   \n",
       "4           0.893434          0.893515        0.893474       0.000040   \n",
       "\n",
       "    rank_test_rmse  mean_fit_time  std_fit_time  mean_test_time  \\\n",
       "7                1       2.306833      0.004266        0.677244   \n",
       "9                2       3.600934      0.186163        0.794973   \n",
       "11               3       5.557814      0.045481        0.668756   \n",
       "6                4       2.374165      0.014508        0.647510   \n",
       "8                5       3.371479      0.032349        0.616422   \n",
       "0                6       2.346534      0.043830        0.689923   \n",
       "10               7       6.030160      0.482804        0.688143   \n",
       "1                8       2.389229      0.070999        0.741644   \n",
       "3                9       3.436527      0.006205        0.665408   \n",
       "5               10       5.602694      0.062305        0.668211   \n",
       "2               11       3.515481      0.090130        0.670033   \n",
       "4               12       6.183955      0.192634        0.824757   \n",
       "\n",
       "    std_test_time                                             params  \\\n",
       "7        0.006639  {'lr_all': 0.005, 'n_factors': 25, 'reg_all': ...   \n",
       "9        0.108060  {'lr_all': 0.005, 'n_factors': 50, 'reg_all': ...   \n",
       "11       0.000647  {'lr_all': 0.005, 'n_factors': 100, 'reg_all':...   \n",
       "6        0.003196  {'lr_all': 0.005, 'n_factors': 25, 'reg_all': ...   \n",
       "8        0.041925  {'lr_all': 0.005, 'n_factors': 50, 'reg_all': ...   \n",
       "0        0.001761  {'lr_all': 0.0025, 'n_factors': 25, 'reg_all':...   \n",
       "10       0.007303  {'lr_all': 0.005, 'n_factors': 100, 'reg_all':...   \n",
       "1        0.064878  {'lr_all': 0.0025, 'n_factors': 25, 'reg_all':...   \n",
       "3        0.009951  {'lr_all': 0.0025, 'n_factors': 50, 'reg_all':...   \n",
       "5        0.001114  {'lr_all': 0.0025, 'n_factors': 100, 'reg_all'...   \n",
       "2        0.023949  {'lr_all': 0.0025, 'n_factors': 50, 'reg_all':...   \n",
       "4        0.111739  {'lr_all': 0.0025, 'n_factors': 100, 'reg_all'...   \n",
       "\n",
       "    param_lr_all  param_n_factors  param_reg_all  \n",
       "7         0.0050               25           0.10  \n",
       "9         0.0050               50           0.10  \n",
       "11        0.0050              100           0.10  \n",
       "6         0.0050               25           0.02  \n",
       "8         0.0050               50           0.02  \n",
       "0         0.0025               25           0.02  \n",
       "10        0.0050              100           0.02  \n",
       "1         0.0025               25           0.10  \n",
       "3         0.0025               50           0.10  \n",
       "5         0.0025              100           0.10  \n",
       "2         0.0025               50           0.02  \n",
       "4         0.0025              100           0.02  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(gs.cv_results).sort_values(by='rank_test_rmse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rmse': 0.8803006451797001}\n",
      "{'rmse': {'lr_all': 0.005, 'n_factors': 25, 'reg_all': 0.1}}\n"
     ]
    }
   ],
   "source": [
    "print(gs.best_score)\n",
    "print(gs.best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 07. 예측 모델 간의 성능 비교\n",
    "- kNN과 MF(SVD) 사이의 모델 성능 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kNN 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Evaluating RMSE, MAE of algorithm KNNWithMeans on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.8940  0.8874  0.8959  0.8922  0.8922  0.8923  0.0028  \n",
      "MAE (testset)     0.6815  0.6785  0.6855  0.6836  0.6820  0.6822  0.0024  \n",
      "Fit time          7.60    7.49    7.51    7.41    7.39    7.48    0.08    \n",
      "Test time         13.08   12.32   12.36   12.36   12.31   12.49   0.30    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([0.89395714, 0.88743407, 0.8958937 , 0.89222901, 0.89222254]),\n",
       " 'test_mae': array([0.68147979, 0.67845507, 0.68553271, 0.68362014, 0.68197489]),\n",
       " 'fit_time': (7.600543975830078,\n",
       "  7.492369651794434,\n",
       "  7.514346361160278,\n",
       "  7.412439584732056,\n",
       "  7.39105749130249),\n",
       " 'test_time': (13.083563566207886,\n",
       "  12.317754030227661,\n",
       "  12.362648010253906,\n",
       "  12.3638174533844,\n",
       "  12.313887119293213)}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_options = {\n",
    "    'name': 'msd',\n",
    "    'user_based': False\n",
    "}\n",
    "\n",
    "knn = KNNWithMeans(k = 40, min_k = 1, sim_options = sim_options)\n",
    "\n",
    "cross_validate(knn, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVD 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.8646  0.8719  0.8701  0.8779  0.8692  0.8707  0.0043  \n",
      "MAE (testset)     0.6659  0.6714  0.6694  0.6749  0.6695  0.6703  0.0029  \n",
      "Fit time          3.58    3.60    3.58    3.58    3.58    3.59    0.01    \n",
      "Test time         0.30    0.21    0.21    0.21    0.22    0.23    0.03    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([0.86458575, 0.8719132 , 0.87005604, 0.87786239, 0.86923162]),\n",
       " 'test_mae': array([0.66593297, 0.67144204, 0.66944609, 0.67493962, 0.66951888]),\n",
       " 'fit_time': (3.575917959213257,\n",
       "  3.603013038635254,\n",
       "  3.5769147872924805,\n",
       "  3.5842466354370117,\n",
       "  3.584979772567749),\n",
       " 'test_time': (0.3022267818450928,\n",
       "  0.2131941318511963,\n",
       "  0.21445083618164062,\n",
       "  0.21469783782958984,\n",
       "  0.21930265426635742)}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd = SVD(n_factors=25, lr_all=0.005, reg_all=0.1)\n",
    "\n",
    "cross_validate(svd, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
